{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Image\n",
    "import cv2\n",
    "# path \n",
    "path = r'D:\\Profile\\Photos\\id.jpg'\n",
    "# img = cv2.imread(\"1.jpg\")\n",
    "img = cv2.imread(path)  # create object for image\n",
    "cv2.imshow(\"Output\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show vido\n",
    "import cv2\n",
    "# path=  r'D:\\Profile\\Photos\\11.mp4'\n",
    "\n",
    "# videcap = cv2.VideoCapture(path)\n",
    "videcap =cv2.VideoCapture(\"vid1.mp4\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = videcap.read()  # read frame by frame and ret is boolen\n",
    "    # Read until video is completed\n",
    "    if ret == True:     # We can remove it \n",
    "        cv2.imshow(\"Output Video\",frame)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break \n",
    "        \n",
    "       \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Live camera \n",
    "import cv2 \n",
    "# If the input is taken from the camera, pass 0 instead of the video file name. \n",
    "\n",
    "vidlive = cv2.VideoCapture(0)\n",
    "\n",
    "# We can set VideoCaptureProperties such as width and height and brightness \n",
    "#https://docs.opencv.org/3.4/d4/d15/group__videoio__flags__base.html#gaeb8dd9c89c10a5c63c139bf7c4f5704d\n",
    "vidlive.set(3,640)\n",
    "vidlive.set(4,400)\n",
    "vidlive.set(10,90)\n",
    "\n",
    "while True:\n",
    "    ret, frame = vidlive.read() \n",
    "    if ret == True:     \n",
    "        cv2.imshow(\"Output Video\",frame)\n",
    "        # Press Q on keyboard to  exit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    else:\n",
    "        break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidlive.set(3,640)\n",
    "vidlive.set(4,400)\n",
    "vidlive.set(10,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(531, 413, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic image processing functions\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"5.jpg\")  # create object for image\n",
    "print(img.shape)\n",
    "#cv2.cvtColor() method\n",
    "imGray =cv2.cvtColor(img,cv2.COLOR_BGRA2GRAY)  # Open CV is working with BGB \n",
    "# imLab =cv2.cvtColor(img,cv2.COLOR_BGR2Lab)\n",
    "# imHSV =cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Gaussian  Blur\n",
    "# imgGBlur = cv2.GaussianBlur(img,(3,3),0)\n",
    "imgGBlur = cv2.GaussianBlur(imGray,(3,3),0)\n",
    "# imgBlur2 = cv2.GaussianBlur(img,(21,21),0) more kernal size, more bluring \n",
    "imgEdgeCanny = cv2.Canny(img,120,100)  # we can decrease the edges by increase threshold\n",
    "imgEdgeCanny2 = cv2.Canny(img,20,50)\n",
    "# Dialation and Erode for image to make edge thicker or thinner\n",
    "kernelmatrix = np.ones((5, 5), np.uint8)\n",
    "imgDilate = cv2.dilate(imgEdgeCanny,kernelmatrix,1)\n",
    "imgErode = cv2.erode(imgDilate,kernelmatrix,1)\n",
    "\n",
    "cv2.imshow(\"Orginal\",img)\n",
    "cv2.imshow(\"Gray Image\",imGray)\n",
    "cv2.imshow(\"Blur Image\",imgGBlur)\n",
    "cv2.imshow(\"Canny Edge Image\",imgEdgeCanny)\n",
    "cv2.imshow(\"imgEdgeCanny2 Image\",imgEdgeCanny2)\n",
    "cv2.imshow(\"Dilated Image\",imgDilate)\n",
    "cv2.imshow(\"Eroded Image\",imgErode)\n",
    "cv2.waitKey(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(721, 900, 3)\n",
      "(500, 300, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Resizing and cropping image\n",
    "import cv2\n",
    "img = cv2.imread(\"1.jpg\")  # create object for image\n",
    "print(img.shape)  # height and width and channel\n",
    "\n",
    "resizedimg = cv2.resize(img,(300,500)) # here width then height\n",
    "print(resizedimg.shape)  # height and width and channel\n",
    "\n",
    "croppedimg = img[100:300,200:550]\n",
    "\n",
    "cv2.imshow(\"Orginal\",img)\n",
    "cv2.imshow(\"Resized Image\",resizedimg)\n",
    "cv2.imshow(\"Cropped Image\",croppedimg)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 600)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drawing shapes, lines with Color , then adding text\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.ones((600,600))  # white\n",
    "img2 = np.zeros((600,600))  # black\n",
    "imgcolor = np.zeros((600,600,3),np.uint8)\n",
    "\n",
    "print(img.shape)\n",
    "# imgcolor[:]=0,0,255 # BGR=00R(255 max)  whole image\n",
    "imgcolor[200:500,300:400]=0,0,255 # BGR=00R(255 max) part of image\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"White\",img)\n",
    "cv2.imshow(\"Black\",img2)\n",
    "cv2.imshow(\"Colored Image\",imgcolor)\n",
    "cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# imgcolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drawing lines, rectangle with Color , then adding text\n",
    "# https://www.cocyer.com/drawing-lines-on-images-using-cv2-line-in-python-opencv/#:~:text=Drawing%20Lines%20on%20Images%20Using%20cv2.line%20%28%29%20in,%280%2C0%29%2C%20%28width%2C%20height%29%2C%20%280%2C0%2C255%29%2C%2012%29%203%20Display%20image\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "imgcolor = np.zeros((600,600,3),np.uint8)\n",
    "imgcolor2 = np.zeros((600,600,3),np.uint8)  # we can't use ones matrix here to make white background because it is color from 0 to 255\n",
    "imgcolor2[:]=255,255,255     # so if we want to back white background we will make all BGR=255 255 255 \n",
    "height = imgcolor.shape[0]\n",
    "width = imgcolor.shape[1]\n",
    "# Line cv2.line : starting point, ending point, color, width\n",
    "cv2.line(imgcolor, (0,0),(300,450),(255,0,0),5)\n",
    "cv2.line(imgcolor2,(0,0),(width,height),(255,255,0),5)\n",
    "\n",
    "cv2.rectangle(imgcolor, (0,0),(300,450),(255,0,255),5)\n",
    "cv2.rectangle(imgcolor, (320,400),(500,560),(255,0,255),-1)  # Thickness of -1 will fill the entire shape\n",
    "cv2.circle(imgcolor,(420,200),30,(0,0,255),3)  # central point, radius\n",
    "cv2.putText(imgcolor,\"Hello opencv\" ,(330,100),cv2.FONT_HERSHEY_COMPLEX,2,(0,255,255),3)  # text,location,font type,scale,color,thinkness\n",
    "\n",
    "cv2.imshow(\"Drawing line\",imgcolor )\n",
    "cv2.imshow(\"Drawing line2\",imgcolor2 )\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Warping Perspective and transformations\n",
    "# https://www.pyimagesearch.com/2014/05/05/building-pokedex-python-opencv-perspective-warping-step-5-6/\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Cards2.jpg\")\n",
    "\n",
    "width,height = 180,250 # inital for new points(location)\n",
    "points= np.float32([[250,129],[416,164],[197,368],[367,403]])\n",
    "newpoints = np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "matrixTran = cv2.getPerspectiveTransform(points,newpoints) #transform\n",
    "imgWrapOut = cv2.warpPerspective(img,matrixTran,(width,height))  #warp Perspective\n",
    "\n",
    "cv2.imshow(\"Cards\", img)\n",
    "cv2.imshow(\"Out Card\", imgWrapOut)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack and concatenate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack and concatenate images in one window  by using numpy h/vstack() or opencv h/vconcat ()\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Cards2.jpg\")\n",
    "# img2 = cv2.imread(\"5.jpg\")\n",
    "# They should have the same shape and number of cannels since they are matrics\n",
    "Hstackedimg = np.hstack((img,img))  \n",
    "Vstackedimg = np.vstack((img,img))\n",
    "\n",
    "cv2.imshow(\"Horzontal Stack\",Hstackedimg)\n",
    "cv2.imshow(\"Vertical Stack\",Vstackedimg)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# BUT thet face two issues, firstly the matrics should have the same shape and channels and also we can't chanhe in scale which is not optimim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hconcat(): It is used as cv2.hconcat() to concatenate images horizontally. Here h means horizontal.\n",
    "# https://www.geeksforgeeks.org/concatenate-images-using-opencv-in-python/\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"Cards2.jpg\")\n",
    "# img2 = cv2.imread(\"5.jpg\")\n",
    "# They should have the same shape and number of cannels since they are matrics\n",
    "Hstackedimg = cv2.hconcat((img,img))  \n",
    "Vstackedimg = cv2.vconcat((img,img))\n",
    "\n",
    "cv2.imshow(\"Horzontal Stack\",Hstackedimg)\n",
    "cv2.imshow(\"Vertical Stack\",Vstackedimg)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/concatenate-images-using-opencv-in-python/\n",
    "# define a function for vertically \n",
    "# concatenating images of different\n",
    "# widths \n",
    "import cv2\n",
    "img = cv2.imread(\"Cards2.jpg\")\n",
    "img2 = cv2.imread(\"5.jpg\")\n",
    "\n",
    "def vconcat_resize(img_list, interpolation \n",
    "                   = cv2.INTER_CUBIC):\n",
    "      # take minimum width\n",
    "    w_min = min(img.shape[1] \n",
    "                for img in img_list)\n",
    "      \n",
    "    # resizing images\n",
    "    im_list_resize = [cv2.resize(img,\n",
    "                      (w_min, int(img.shape[0] * w_min / img.shape[1])),\n",
    "                                 interpolation = interpolation)\n",
    "                      for img in img_list]\n",
    "    # return final image\n",
    "    return cv2.vconcat(im_list_resize)\n",
    "\n",
    "  \n",
    "# function calling\n",
    "img_v_resize = vconcat_resize([img, img2, img])\n",
    "\n",
    "# Resize again the output ( we can do it inside the function or outside)\n",
    "# img_h_resize2 = cv2.resize(img_h_resize, dsize = (900,900))\n",
    "img_v_resize2 = cv2.resize(img_v_resize, dsize = (0,0),fx = 0.5, fy = 0.5) # This is better since we just rezise by scale\n",
    "\n",
    "cv2.imshow(\"vconcat_resize.jpg\",img_v_resize)\n",
    "cv2.imshow(\"vconcat_resize2.jpg\",img_v_resize2)\n",
    "\n",
    "# cv2.imshow(\"Vertical Stack\",Vstackedimg)\n",
    "cv2.waitKey(0)\n",
    "# show the output image\n",
    "# cv2.imwrite('vconcat_resize.jpg', img_v_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/concatenate-images-using-opencv-in-python/\n",
    "# define a function for horizontally \n",
    "# concatenating images of different\n",
    "# heights \n",
    "import cv2\n",
    "img = cv2.imread(\"Cards2.jpg\")\n",
    "img2 = cv2.imread(\"5.jpg\")\n",
    "\n",
    "def hconcat_resize(img_list, \n",
    "                   interpolation \n",
    "                   = cv2.INTER_CUBIC):\n",
    "      # take minimum hights\n",
    "    h_min = min(img.shape[0] \n",
    "                for img in img_list)\n",
    "      \n",
    "    # image resizing \n",
    "    im_list_resize = [cv2.resize(img,\n",
    "                       (int(img.shape[1] * h_min / img.shape[0]),\n",
    "                        h_min), interpolation\n",
    "                                 = interpolation) \n",
    "                      for img in img_list]\n",
    "      \n",
    "    # return final image\n",
    "    return cv2.hconcat(im_list_resize)\n",
    "  \n",
    "# function calling\n",
    "img_h_resize = hconcat_resize([img, img2, img])\n",
    "\n",
    "# Resize again the output\n",
    "# img_h_resize2 = cv2.resize(img_h_resize, dsize = (900,900))\n",
    "img_h_resize2 = cv2.resize(img_h_resize, dsize = (0,0),fx = 0.5, fy = 0.5) # This is better since we just rezise by scale\n",
    "\n",
    "# show the Output image\n",
    "\n",
    "cv2.imshow('hconcat_resize.jpg', img_h_resize)\n",
    "cv2.imshow('hconcat_resize2.jpg', img_h_resize2)\n",
    "\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating vertically images of the same size  and horizontally\n",
    "import cv2\n",
    "img = cv2.imread(\"2.jpg\")\n",
    "\n",
    "def concat_vh(list_2d):\n",
    "    \n",
    "      # return final image\n",
    "    return cv2.vconcat([cv2.hconcat(list_h) \n",
    "                        for list_h in list_2d])\n",
    "# image resizing\n",
    "img1_s = cv2.resize(img, dsize = (0,0),\n",
    "                    fx = 0.2, fy = 0.2)\n",
    "  \n",
    "# function calling\n",
    "img_tile = concat_vh([[img1_s, img1_s, img1_s],\n",
    "                      [img1_s, img1_s, img1_s],\n",
    "                      [img1_s, img1_s, img1_s]])\n",
    "# show the output image\n",
    "cv2.imshow('concat_vh.jpg', img_tile)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function for concatenating images of different sizes in vertical and horizontal tiles\n",
    "\n",
    "import cv2\n",
    "img1 = cv2.imread(\"4.jpg\")\n",
    "img2 = cv2.imread(\"5.jpg\")\n",
    "img3 = cv2.imread(\"3.jpg\")\n",
    "img4= cv2.cvtColor(img2,cv2.COLOR_BGRA2GRAY)\n",
    "\n",
    "def concat_tile_resize(list_2d, \n",
    "                       interpolation = cv2.INTER_CUBIC):\n",
    "      # function calling for every \n",
    "    # list of images\n",
    "    img_list_v = [hconcat_resize(list_h, \n",
    "                                 interpolation = cv2.INTER_CUBIC) \n",
    "                  for list_h in list_2d]\n",
    "      \n",
    "    # return final image\n",
    "    return vconcat_resize(img_list_v, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "\n",
    "# function calling\n",
    "im_tile_resize = concat_tile_resize([[img1],\n",
    "                                     [img1, img2,\n",
    "                                      img1, img3, img1],\n",
    "                                     [img1, img2, img3]])\n",
    "\n",
    "\n",
    "# REsize again\n",
    "im_tile_resize2 = cv2.resize(im_tile_resize, dsize = (0,0),\n",
    "                    fx = 0.5, fy = 0.5)\n",
    "# show the image\n",
    "cv2.imshow('concat_tile_resize.jpg', im_tile_resize2)\n",
    "# cv2.imshow('grey.jpg', img4) \n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Still we face issue if we need to concate two images with different channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here the another function  to stack between two images with different channels\n",
    "# https://github.com/murtazahassan/Learn-OpenCV-in-3-hours/blob/master/chapter6.py\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "img = cv2.imread('1.jpg')\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "imgStack = stackImages(0.3,([img,imgGray,img],[img,img,img]))\n",
    "\n",
    "# imgHor = np.hstack((img,img))\n",
    "# imgVer = np.vstack((img,img))\n",
    "#\n",
    "# cv2.imshow(\"Horizontal\",imgHor)\n",
    "# cv2.imshow(\"Vertical\",imgVer)\n",
    "cv2.imshow(\"ImageStack\",imgStack)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  bitwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "blank = np.zeros((400,400), dtype='uint8')\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "circle = cv.circle(blank.copy(), (200,200), 200, 255, -1)\n",
    "\n",
    "cv.imshow('Rectangle', rectangle)\n",
    "cv.imshow('Circle', circle)\n",
    "\n",
    "# bitwise AND --> intersecting regions\n",
    "bitwise_and = cv.bitwise_and(rectangle, circle)\n",
    "cv.imshow('Bitwise AND', bitwise_and)\n",
    "\n",
    "# bitwise OR --> non-intersecting and intersecting regions\n",
    "bitwise_or = cv.bitwise_or(rectangle, circle)\n",
    "cv.imshow('Bitwise OR', bitwise_or)\n",
    "\n",
    "# bitwise XOR --> non-intersecting regions\n",
    "bitwise_xor = cv.bitwise_xor(rectangle, circle)\n",
    "cv.imshow('Bitwise XOR', bitwise_xor)\n",
    "\n",
    "# bitwise NOT\n",
    "bitwise_not = cv.bitwise_not(circle)\n",
    "cv.imshow('Circle NOT', bitwise_not)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1600, 3) (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('2.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')  # :2 to be same shape (two dimensions)\n",
    "cv.imshow('Blank Image', blank)\n",
    "cv.waitKey(0)\n",
    "print(img.shape, blank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('birds.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 200, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "cv.imshow('C', circle)\n",
    "cv.imshow('R', rectangle)\n",
    "maskc= cv.bitwise_and(img,img,mask=circle)\n",
    "cv.imshow('MC', maskc)\n",
    "\n",
    "# weird_shape = cv.bitwise_and(circle,rectangle)\n",
    "# cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "# masked = cv.bitwise_and(img,img,mask=weird_shape)\n",
    "# cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('birds.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "blank = np.zeros(img.shape[:2], dtype='uint8')\n",
    "cv.imshow('Blank Image', blank)\n",
    "\n",
    "circle = cv.circle(blank.copy(), (img.shape[1]//2 + 45,img.shape[0]//2), 200, 255, -1)\n",
    "\n",
    "rectangle = cv.rectangle(blank.copy(), (30,30), (370,370), 255, -1)\n",
    "\n",
    "weird_shape = cv.bitwise_and(circle,rectangle)\n",
    "cv.imshow('Weird Shape', weird_shape)\n",
    "\n",
    "masked = cv.bitwise_and(img,img,mask=weird_shape)\n",
    "cv.imshow('Weird Shaped Masked Image', masked)\n",
    "\n",
    "cv.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150.0 [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "img = cv.imread('birds.jpg')\n",
    "cv.imshow('Cats', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Simple Thresholding\n",
    "threshold, thresh = cv.threshold(gray, 150, 255, cv.THRESH_BINARY )\n",
    "cv.imshow('Simple Thresholded', thresh)\n",
    "\n",
    "threshold, thresh_inv = cv.threshold(gray, 150, 255, cv.THRESH_BINARY_INV )\n",
    "cv.imshow('Simple Thresholded Inverse', thresh_inv)\n",
    "\n",
    "# Adaptive Thresholding (Make computer find the best threshold for me)\n",
    "adaptive_thresh = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 9)\n",
    "cv.imshow('Adaptive Thresholding', adaptive_thresh)\n",
    "\n",
    "cv.waitKey(0)\n",
    "print(threshold, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection and gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are different topics however in OpenCV there are common functions that can be used for them \n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread('nile.jpg')\n",
    "cv.imshow('Orginal', img)\n",
    "\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "cv.imshow('Gray', gray)\n",
    "\n",
    "# Laplacian\n",
    "lap = cv.Laplacian(gray, cv.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv.imshow('Laplacian', lap)\n",
    "\n",
    "# Sobel \n",
    "sobelx = cv.Sobel(gray, cv.CV_64F, 1, 0)\n",
    "sobely = cv.Sobel(gray, cv.CV_64F, 0, 1)\n",
    "combined_sobel = cv.bitwise_or(sobelx, sobely)\n",
    "\n",
    "cv.imshow('Sobel X', sobelx)\n",
    "cv.imshow('Sobel Y', sobely)\n",
    "cv.imshow('Combined Sobel', combined_sobel)\n",
    "\n",
    "canny = cv.Canny(gray, 150, 175)\n",
    "cv.imshow('Canny', canny)\n",
    "cv.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
